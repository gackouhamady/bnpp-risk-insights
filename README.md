# ğŸš€ Objectif du projet
Prototyper un **DataHub Risk & Customer Insights** pour BNP Paribas CoE Data Science, couvrant :

- **Ingestion & prÃ©paration** de donnÃ©es (comptes, transactions, KYC) en Python & SQL  
- **Construction dâ€™un datamart** Risk & Customer Analytics (star schema)  
- **Reporting & dashboards** interactifs avec Power BI ou Tableau  
- **ModÃ©lisation prÃ©dictive** : scoring dÃ©faut (Logistic Regression) et churn (XGBoost)  
- **DÃ©tection dâ€™anomalies** transactions (Isolation Forest)  
- **Pipeline MLOps lÃ©ger** (Airflow ou scripts batch + MLflow)  
- **Documentation & bonnes pratiques** (versioning, tests, GDPR/anonymisation)  

---

## ğŸ“… Planning dÃ©taillÃ© sur 5 jours ouvrÃ©s (+ 2 jours de buffer)

| Jour   | TÃ¢ches clÃ©s                                                                                                                                                                                                  |
|:------:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Jour 1** | - **Init repo & env** : `git init` + `.gitignore` + venv Python  
  â€¢ `requirements.txt` (pandas, numpy, scikit-learn, sqlalchemy, mlflow, fastapi, uvicorn, streamlitâ€¦)  
  - **Data sampling** : CSV simulÃ©s de comptes clients, transactions et fichier KYC (1 000 lignes chacun) |
| **Jour 2** | - **ETL & datamart** (`src/etl.py`) :  
  â€¢ Extraction CSV â†’ Pandas â†’ nettoyage (formats, doublons)  
  â€¢ Chargement dans SQLite ou Postgres local  
  â€¢ CrÃ©ation des tables fact (`transactions`, `events`) et dimensions (`clients`, `comptes`, `temps`) |
| **Jour 3** | - **Reporting & BI** (`src/reporting.py`) :  
  â€¢ Prototype de dashboard Power BI/Tableau : KPIs clÃ©s (volume transactions, portefeuille actif)  
  â€¢ Automatisation dâ€™exports CSV via Python/VBA pour refresh quotidien |
| **Jour 4** | - **ModÃ©lisation prÃ©dictive** :  
  â€¢ `src/model_default.py` â€“ Logistic Regression pour dÃ©faut de paiement (features : montant moyen, frÃ©quenceâ€¦)  
  â€¢ `src/model_churn.py` â€“ XGBoost pour prÃ©dire churn (features : anciennetÃ©, solde moyenâ€¦)  
  â€¢ Ã‰valuation : AUC, confusion matrix, rapport classification |
| **Jour 5** | - **DÃ©tection dâ€™anomalies** (`src/anomaly.py`) :  
  â€¢ Isolation Forest sur montants & frÃ©quences de transaction  
  â€¢ Visualisation des outliers dans Streamlit  
  - **Pipeline & MLOps** (`src/pipeline.py`) :  
  â€¢ Orchestration ETL â†’ scoring â†’ anomaly â†’ gÃ©nÃ©ration de rapport JSON  
  â€¢ Tracking dâ€™expÃ©riences MLflow (params & metrics) |
| **Jour 6** | - **Prototype dâ€™interface** (`src/app.py`) :  
  â€¢ Streamlit local pour visualiser dashboards, lancer scoring & anomaly  
  â€¢ FastAPI exposant endpoints `/score_default`, `/detect_anomaly` |
| **Jour 7** | - **Documentation & tests** :  
  â€¢ `README.md` (installation, usage, migration Dataiku/GCP)  
  â€¢ Diagramme ER dans `docs/`  
  â€¢ Tests unitaires pytest pour chaque module  
  - **Packaging & livraison** :  
  â€¢ `requirements.txt` final (`pip freeze`)  
  â€¢ Dockerfile (base `python:3.10`) pour app Streamlit + FastAPI  
  â€¢ Commit & push sur GitHub + plan de dÃ©ploiement Cloud Run/Vertex AI |

---

## âš™ï¸ Structure Git finale

```bash
bnpp-risk-insights/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # CSV simulÃ©s comptes, transactions, KYC
â”‚   â””â”€â”€ processed/                 # tables cleansed
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ datamart_schema.png        # diagramme star schema
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ etl.py                     # extraction, nettoyage, chargement
â”‚   â”œâ”€â”€ reporting.py               # exports CSV & templates BI
â”‚   â”œâ”€â”€ model_default.py           # scoring dÃ©faut (Logistic Regression)
â”‚   â”œâ”€â”€ model_churn.py             # churn (XGBoost)
â”‚   â”œâ”€â”€ anomaly.py                 # Isolation Forest
â”‚   â”œâ”€â”€ pipeline.py                # orchestration + MLflow
â”‚   â””â”€â”€ app.py                     # Streamlit + FastAPI
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_etl.py
â”‚   â”œâ”€â”€ test_reporting.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
