# ğŸš€ Project Objective

Prototype a **DataHub Risk & Customer Insights** for BNP Paribas CoE Data Science, covering:

* **Data ingestion & preparation** (accounts, transactions, KYC) in Python & SQL
* **Building a Risk & Customer Analytics datamart** (star schema)
* **Interactive reporting & dashboards** with Power BI or Tableau
* **Predictive modeling**: default scoring (Logistic Regression) and churn (XGBoost)
* **Transaction anomaly detection** (Isolation Forest)
* **Lightweight MLOps pipeline** (Airflow or batch scripts + MLflow)
* **Documentation & best practices** (versioning, testing, GDPR/anonymization)

---

## ğŸ“… Detailed 5-Day Working Plan (+2 Days Buffer)

| **Day**       | **Key Tasks** |
|---------------|---------------|
| **Day 1**      | - **Init repo & env**: `git init` + `.gitignore` + Python venv  <br> - `requirements.txt` (pandas, numpy, scikit-learn, sqlalchemy, mlflow, fastapi, uvicorn, streamlitâ€¦)  <br> - **Data sampling**: simulated CSVs of client accounts, transactions, and KYC file (1,000 rows each) |
| **Day 2**      | - **ETL & datamart** (`src/etl.py`):  <br>  â€¢ Extraction CSV â†’ Pandas â†’ cleaning (formats, duplicates)  <br>  â€¢ Loading into local SQLite or Postgres  <br>  â€¢ Creation of fact tables (`transactions`, `events`) and dimensions (`clients`, `accounts`, `time`) |
| **Day 3**      | - **Reporting & BI** (`src/reporting.py`):  <br>  â€¢ Prototype Power BI/Tableau dashboard: key KPIs (transaction volume, active portfolio)  <br>  â€¢ Automate CSV exports via Python/VBA for daily refresh |
| **Day 4**      | - **Predictive modeling**:  <br>  â€¢ `src/model_default.py`: Logistic Regression for payment default (features: average amount, frequencyâ€¦)  <br>  â€¢ `src/model_churn.py`: XGBoost to predict churn (features: tenure, average balanceâ€¦)  <br>  â€¢ Evaluation: AUC, confusion matrix, classification report |
| **Day 5**      | - **Anomaly detection** (`src/anomaly.py`):  <br>  â€¢ Isolation Forest on transaction amounts & frequencies  <br>  â€¢ Visualization of outliers in Streamlit  <br> - **Pipeline & MLOps** (`src/pipeline.py`):  <br>  â€¢ Orchestration ETL â†’ scoring â†’ anomaly â†’ JSON report generation  <br>  â€¢ MLflow experiment tracking (params & metrics) |
| **Day 6** *(Buffer)* | - **Interface prototype** (`src/app.py`):  <br>  â€¢ Local Streamlit to view dashboards, run scoring & anomaly  <br>  â€¢ FastAPI exposing endpoints `/score_default`, `/detect_anomaly` |
| **Day 7** *(Buffer)* | - **Documentation & tests**:  <br>  â€¢ `README.md` (installation, usage, Dataiku/GCP migration)  <br>  â€¢ ER diagram in `docs/`  <br>  â€¢ Pytest unit tests for each module  <br> - **Packaging & delivery**:  <br>  â€¢ Final `requirements.txt` (`pip freeze`)  <br>  â€¢ Dockerfile (base `python:3.10`) for Streamlit + FastAPI app  <br>  â€¢ Commit & push to GitHub + Cloud Run/Vertex AI deployment plan |

## âš™ï¸ Final Git structure

```bash
bnpp-risk-insights/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # simulated accounts, transactions, KYC CSVs
â”‚   â””â”€â”€ processed/                 # cleansed tables
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ datamart_schema.png        # star schema diagram
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ etl.py                     # extraction, cleaning, loading
â”‚   â”œâ”€â”€ reporting.py               # CSV exports & BI templates
â”‚   â”œâ”€â”€ model_default.py           # default scoring (Logistic Regression)
â”‚   â”œâ”€â”€ model_churn.py             # churn (XGBoost)
â”‚   â”œâ”€â”€ anomaly.py                 # Isolation Forest
â”‚   â”œâ”€â”€ pipeline.py                # orchestration + MLflow
â”‚   â””â”€â”€ app.py                     # Streamlit + FastAPI
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_etl.py
â”‚   â”œâ”€â”€ test_reporting.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```



## Architecture summary  

``` text

1. Data Sources
   â”œâ”€ Client accounts (CSV)
   â”œâ”€ Transactions (CSV)
   â””â”€ KYC (CSV)

2. Ingestion & Preparation (ETL)
   â”œâ”€ Extraction (pandas)
   â”œâ”€ Cleaning (formats, duplicates, GDPR)
   â””â”€ Loading (SQLAlchemy â†’ SQLite/Postgres)

3. Datamart (star schema)
   â”œâ”€ Fact tables
   â”‚   â”œâ”€ transactions
   â”‚   â””â”€ events
   â””â”€ Dimension tables
       â”œâ”€ clients
       â”œâ”€ accounts
       â””â”€ time

4. Storage & Traceability
   â”œâ”€ Optimized SQL database
   â””â”€ MLflow (tracking runs: parameters, metrics, artifacts)

5. Analytical Modules
   â”œâ”€ Default scoring (logistic regression)
   â”œâ”€ Churn prediction (XGBoost)
   â””â”€ Anomaly detection (Isolation Forest)

6. MLOps Orchestration
   â”œâ”€ Airflow or batch scripts
   â””â”€ Pipeline ETL â†’ scoring â†’ anomaly â†’ JSON reports

7. Interfaces
   â”œâ”€ Streamlit (dashboards & manual execution)
   â””â”€ FastAPI (endpoints `/score_default` & `/detect_anomaly`)

8. Containerization & Deployment
   â”œâ”€ Docker (Python 3.10)
   â””â”€ Cloud Run / Vertex AI (auto-scaling, monitoring)

9. Quality & Governance
   â”œâ”€ Unit tests (Pytest)
   â”œâ”€ Documentation (README, ER diagram)
   â””â”€ Git conventions and code reviews

```
