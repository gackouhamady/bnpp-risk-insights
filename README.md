# ğŸš€ DataHub Risk & Customer Insights

**Prototype developed for the BNPâ€¯Paribas Data Science CoE:**

* Data ingestion & preparation
* Analytics datamart (star schema)
* Interactive reporting & dashboards
* Predictive modeling (default scoring & churn prediction)
* Transaction anomaly detection
* Lightweight MLOps pipeline (scripts + MLflow)
* REST API (FastAPI) & Streamlit UI
* Docker container

---

## ğŸ“Š Model Performance Summary

| Model                | AUC    | Precision (0â€¯/â€¯1) | Recall (0â€¯/â€¯1) | F1-score (0â€¯/â€¯1) | Accuracy |
| -------------------- | ------ | ----------------- | -------------- | ---------------- | -------- |
| **Default Scoring**  | 0.9981 | 0.97â€¯/â€¯0.97       | 0.99â€¯/â€¯0.89    | 0.98â€¯/â€¯0.93      | 0.97     |
| **Churn Prediction** | 0.9167 | 0.96â€¯/â€¯1.00       | 1.00â€¯/â€¯0.83    | 0.98â€¯/â€¯0.91      | 0.97     |

> **Default Scoring** (Logistic Regression)
>
> * AUC: 0.9981 (almost perfect separation)
> * Accuracy: 97% (192 samples)

> **Churn Prediction** (XGBoost)
>
> * AUC: 0.9167 (excellent churn vs. retention discrimination)
> * Accuracy: 97% (30 samples)

---

## ğŸ“… Detailed Day-by-Day Plan

| Day | Deliverables                                                                                                                                                     |
| --- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1   | - Repo & venv initialization, `.gitignore`  <br> - `requirements.txt`  <br> - Generate 1,000 synthetic rows (accounts, transactions, KYC)                        |
| 2   | - ETL & datamart (`src/etl.py`): extract raw CSVs, clean data, create star schema, load into SQLite/PostgreSQL                                                   |
| 3   | - Reporting & BI (`src/reporting.py`): timestamped CSV exports & Power BI/Tableau prototype  <br> - Daily refresh script                                         |
| 4   | - Default scoring (`src/model_default.py`)  <br> - Churn prediction (`src/model_churn.py`)  <br> - AUC, confusion matrix, classification report                  |
| 5   | - Anomaly detection (`src/anomaly.py`): Isolation Forest & Streamlit UI  <br> - Partial orchestration                                                            |
| 6   | - Full pipeline (`src/pipeline.py`): ETL â†’ default & churn scoring â†’ anomalies â†’ MLflow â†’ JSON report  <br> - FastAPI endpoints (`src/app.py`)                   |
| 7   | - Write `README.md`  <br> - ER diagram (`docs/datamart_schema.png`)  <br> - Unit tests (Pytest)  <br> - `Dockerfile` (Pythonâ€¯3.10)  <br> - Cloud deployment plan |

---

## âš™ï¸ Repository Structure

```bash
bnpp-risk-insights/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # synthetic CSVs: accounts, transactions, KYC
â”‚   â”œâ”€â”€ processed/           # SQLite datamart (`risk_insights.db`)
â”‚   â””â”€â”€ exports/             # timestamped CSVs for BI
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ datamart_schema.png  # star schema ER diagram
â”‚   â””â”€â”€ anomaly_ui.png       # Streamlit anomaly detection screenshot
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ logreg_default.pkl   # default scoring model
â”‚   â””â”€â”€ xgb_churn.json       # churn prediction model
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ report_YYYYMMDD_HHMMSS.json  # JSON reports per run
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generate_data.py     # synthetic data generator
â”‚   â”œâ”€â”€ etl.py               # extract, transform, load
â”‚   â”œâ”€â”€ reporting.py         # CSV exports & BI prep
â”‚   â”œâ”€â”€ model_default.py     # logistic regression scoring
â”‚   â”œâ”€â”€ model_churn.py       # XGBoost churn prediction
â”‚   â”œâ”€â”€ anomaly.py           # Isolation Forest + Streamlit UI
â”‚   â”œâ”€â”€ pipeline.py          # orchestration + MLflow + JSON report
â”‚   â””â”€â”€ app.py               # FastAPI application
â”œâ”€â”€ tests/                   # Pytest unit tests
â”œâ”€â”€ Dockerfile               # multi-stage Pythonâ€¯3.10 container
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # project documentation
```

---

## ğŸ›  Installation & Usage

1. **Clone & prepare venv**

   ```bash
   git clone <repo>
   python -m venv venv
   # Windows
   .\\venv\\Scripts\\Activate.ps1
   ```
2. **Install dependencies**

   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```
3. **Generate sample data**

   ```bash
   python src/generate_data.py
   ```
4. **Build the datamart**

   ```bash
   python src/etl.py
   ```
5. **Export for BI**

   ```bash
   python src/reporting.py
   ```
6. **Train models**

   ```bash
   python src/model_default.py
   python src/model_churn.py
   ```
7. **Run the anomaly UI**

   ```bash
   streamlit run src/anomaly.py
   ```

   <img src="docs/anomaly.png" alt="Streamlit Anomaly UI" width="700"/>
8. **Orchestrate & generate report**

   ```bash
   python src/pipeline.py
   ```
9. **Start the API**

   ```bash
   python -m uvicorn src.app:app --reload --host 0.0.0.0 --port 8000
   ```

   > Access the docs at `http://localhost:8000/docs`
10. **Run unit tests**

    ```bash
    pytest --maxfail=1 -q
    ```
11. **Docker**

    ```bash
    docker build -t risk-insights:latest .
    docker run -p 8000:8000 risk-insights:latest
    ```

---

## ğŸ”’ Governance & Ethics

* Synthetic data only â†’ no real PII
* GDPR-compliant: anonymization & privacy by design
* Transparent, versioned code with unit tests
* Ready for industrialization (Dataiku / GCP)

*An industrial-grade blueprint for risk & customer analytics in banking.*
